{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import source code\n",
    "import sys, os, glob\n",
    "from numpy import *\n",
    "sys.path.append('new_src')\n",
    "from Preparation import *\n",
    "from PosteriorSampler import *\n",
    "from Analysis_new import *\n",
    "from Restraint import *\n",
    "from init_res import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Initialization #############\n",
    "# Specify necessary argument values\n",
    "\n",
    "# REQUIRED: specify number of states\n",
    "states=100\n",
    "\n",
    "# REQUIRED: specify directory of input data (BICePs readable format)\n",
    "dataFiles = 'noe_J'   \n",
    "\n",
    "# REQUIRED: sort data and figure out what experimental restraints are included for each state\n",
    "data = sort_data(dataFiles)\n",
    "\n",
    "# REQUIRED: energy file name of each state (computational prior distribution)\n",
    "energies_filename =  'energy.dat'\n",
    "energies = loadtxt(energies_filename)\n",
    "energies -= energies.min()  # set ground state to zero, just in case\n",
    "\n",
    "# REQUIRED: specify outcome directory of BICePs sampling\n",
    "outdir = 'results_ref_normal'\n",
    "# Make a new directory if we have to\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "\n",
    "# REQUIRED: number of MCMC steps for each lambda\n",
    "nsteps = 10000000 # 10000000\n",
    "\n",
    "    \n",
    "# REQUIRED: specify how many lambdas to sample (more lambdas will provide higher accuracy but slower the whole process, lambda=0.0 and 1.0 are necessary)\n",
    "lambda_values = [0.0,0.5,1.0]\n",
    "\n",
    "# OPTIONAL but RECOMMENDED: print experimental restraints included (a chance for double check)\n",
    "res = list_res(data)\n",
    "print res\n",
    "\n",
    "# REQUIRED: specify reference potential to use for each experimental observable\n",
    "# will be in the same order as the printed observables from (print res)\n",
    "ref=['uniform','exp']\n",
    "\n",
    "# OPTIONAL: specify nuisance parameters for each experimnetal observable\n",
    "# will be in the same order as the printed observables from (print res)\n",
    "# only specify if you want to narrow down the default range  \n",
    "uncern=[[0.05,20.0,1.02],[0.05,5.0,1.02]]\n",
    "gamma = [0.2,5.0,1.01]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Main:\n",
    "######################\n",
    "\n",
    "for j in lambda_values:\n",
    "    verbose = False #False\n",
    "    lam = j\n",
    "    # We will instantiate a number of Restraint() objects to construct the ensemble\n",
    "    # experimental data and pre-computed model data are compiled for each state\n",
    "    ensemble = []\n",
    "    for i in range(energies.shape[0]):   # number of states\n",
    "        print '\\n#### STRUCTURE %d ####'%i\n",
    "        ensemble.append([])\n",
    "        for k in range(len(data[0])):   # number of experimental observables\n",
    "            File = data[i][k]\n",
    "            if verbose:\n",
    "                print File\n",
    "            R=init_res('top/%d.pdb'%i,lam,energies[i],ref[k],File,uncern[k],gamma)\n",
    "            ensemble[-1].append(R)\n",
    "        print ensemble\n",
    "        \n",
    "    ##########################################\n",
    "    # Next, let's do posterior MCMC sampling\n",
    "    ########## Posterior Sampling ############\n",
    "\n",
    "    sampler = PosteriorSampler(ensemble)\n",
    "    sampler.compile_nuisance_parameters()\n",
    "\n",
    "    sampler.sample(nsteps)  # number of steps\n",
    "\n",
    "    print 'Processing trajectory...',\n",
    "\n",
    "    sampler.traj.process()  # compute averages, etc.\n",
    "    print '...Done.'\n",
    "\n",
    "    print 'Writing results...',\n",
    "    sampler.traj.write_results(os.path.join(outdir,'traj_lambda%2.2f.npz'%lam))\n",
    "    print '...Done.'\n",
    "    sampler.traj.read_results(os.path.join(outdir,'traj_lambda%2.2f.npz'%lam))\n",
    "\n",
    "    print 'Pickling the sampler object ...',\n",
    "    outfilename = 'sampler_lambda%2.2f.pkl'%lam\n",
    "    print outfilename,\n",
    "    fout = open(os.path.join(outdir, outfilename), 'wb')\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    cPickle.dump(sampler, fout)\n",
    "    fout.close()\n",
    "    print '...Done.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Let's do analysis using MBAR algorithm and plot figures\n",
    "############ MBAR and Figures ###########\n",
    "# Specify necessary argument values\n",
    "\n",
    "A = Analysis(100,dataFiles,outdir)\n",
    "A.plot()\n",
    "\n",
    "# output files include: population information, figure of sampled parameters distribution, BICePs score information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
